/** To run
 *  $ webppl examples/tictactoe/src/experiments.wppl --require .
 *    --require examples/tictactoe/ [--] [--help] [--experiment <experimentID>]
 *    [--scenario <scenarioID>] [--runs <numberOfRunsOfEachScenario>]
 */

/** Tic-tac-toe experiments
 *  They are divided into two parts:
 *  (1) non-cognitive, where mental goals don't feature in agents
 *  utility functions and the sole motivation is to win the game
 *  (2) cognitive, where the scenario is parent vs kid and kid's
 *  satisfaction is considered by the parent
 */

/** AUXILIARY */
/** prints the outcome of the game (should be called at the end) */
let final = function(game, agents, finalState, names) {
  let finalBoard = (!_top.Array.isArray(finalState[0])) ?
    finalState :
    function() {
      //convert into board
      let emptyBoard = repeat(9, getUndefined)
      return reduceL(function(board,move) {
        return arrayReplace(board, move[1], move[0])
      }, emptyBoard, finalState)
    }()
  if (threeInARow(finalBoard, 'X')) {
    display("winner: X")
  } else if (threeInARow(finalBoard, 'O')) {
    display("winner: O")
  } else {
    display("draw")
  }
}

/** PART 1: Non-cognitive Tic-tac-toe
 *  These experiments aim to show that agents with better cognitive
 *  abilities (measured by lookahead parameter) perform better in
 *  tic-tac-toe and also that agent's behaviour depends on their
 *  beliefs of opponent's lookahead
 * */
let lookAheadExperiment = function() {
  let getParams = function(lookAhead) {
    return {
      /** format [physical goal, mental goal] */
      goalCoeffs: [1],
      metaParams: {
        alpha: 1000,
        discountFactor: 0.9,
        lookAhead: lookAhead
      }
    }
  }
  let getInitialState = function(agentID, lookAheadEstimation) {
    let alpha = [undefined, Delta({v: 1000})]
    let discountFactor = [undefined, Delta({v: 0.9})]
    let lookAhead = [undefined, Delta({v: lookAheadEstimation})]
    let belief = [
      Delta({v:["belief over oneself"]}),
      Delta({v:[1]})
    ]
    return {
      belief: (agentID == 0) ?
        belief : arrayReverse(belief),
      mentalEstimations : [undefined, undefined],
      metaParamsEstimations: {
        alpha: (agentID == 0) ?
          alpha : arrayReverse(alpha),
        lookAhead: (agentID == 0) ?
          lookAhead : arrayReverse(lookAhead),
        discountFactor: (agentID == 0) ?
          discountFactor : arrayReverse(discountFactor)
      }
    }
  }
  let getAgent = function(agentID, lookAhead, lookAheadEstimation) {
    return {
      params: getParams(lookAhead),
      initialState: getInitialState(agentID, lookAheadEstimation)
    }
  }

  let scenarios = [
    {
      name: 'strong vs strong and both think their opponent strong',
      agents:
        [
          getAgent(0, 9, 9),
          getAgent(1, 9, 9)
        ],
      options: {
        horizon: 9,
        beliefRepresentation: 'discrete'
      },
      gameSpecificParams: {
        stateRepresentation: 'efficient'
      }
    },
    {
      name: 'strong vs weak but strong thinks opponent strong',
      agents:
        [
          getAgent(0, 9, 9),
          getAgent(1, 3, 3)
        ],
      options: {
        horizon: 9,
        beliefRepresentation: 'discrete'
      },
      gameSpecificParams: {
        stateRepresentation: 'efficient'
      }
    },
    {
      name: 'strong vs weak and strong thinks opponent weak',
      agents:
        [
          getAgent(0, 9, 3),
          getAgent(1, 3, 3)
        ],
      options: {
        horizon: 9,
        beliefRepresentation: 'discrete'
      },
      gameSpecificParams: {
        stateRepresentation: 'efficient'
      }
    },
    {
      name: 'weak vs weak and accurate estimations',
      agents:
        [
          getAgent(0, 3, 3),
          getAgent(1, 3, 3)
        ],
      options: {
        horizon: 9,
        beliefRepresentation: 'discrete'
      },
      gameSpecificParams: {
        stateRepresentation: 'efficient'
      }
    }
  ]

  let callbacks = {
    final
  }

  let names = ['cross','nought']

  let runsDefault = 10

  let runAll = function(repsOpt) {
    let reps = repsOpt || runsDefault
    simulateScenarios(scenarios, makeTicTacToe, names, callbacks, reps)
  }

  let run = function(experimentNumber, repsOpt) {
    assertHasType(experimentNumber, INT_TYPE,
      "lookAheadExperiment: run(): experimentNumber must be an " +
      "index into an array; found: " + toString(experimentNumber))
    assert(experimentNumber >= 0 && experimentNumber < scenarios.length,
      "lookAheadExperiment: run(): experimentNumber out of range: " +
      experimentNumber + "; expected between 0 and " + (scenarios.length - 1))
    let reps = repsOpt || runsDefault
    let scenario = scenarios.slice(experimentNumber, experimentNumber + 1)
    simulateScenarios(scenario, makeTicTacToe, names, callbacks, reps )
  }

  return {
    name: 'lookAheadExperiment',
    desc: "Vary lookahead and lookahead estimation of agents to see how " +
      "that affects game outcomes",
    runsDefault: 10,
    // run,
    // runAll,
    scenarios,
    names,
    callbacks
  }
}()


/** PART 2: Tic-tac-toe with mental component (parent vs kid)
 *
 * */
let parentKidExperiment = function() {
  let getParentParams = function(firstCoeff, lookAhead) {
    return {
      /** format [physical goal, mental goal] */
      goalCoeffs: [firstCoeff, 1 - firstCoeff],
      metaParams: {
        alpha: 100,
        discountFactor: 1,
        lookAhead: lookAhead
      }
    }
  }
  let getParentInitialState = function(lookAheadEstimation) {
    let alpha = [Delta({v: 5}), undefined]
    let discountFactor = [Delta({v: 0.7}), undefined]
    let lookAhead = [Delta({v: lookAheadEstimation}), undefined]
    let belief = [
      Delta({v:[1]}),
      Delta({v:["belief over oneself"]})
    ]
    return {
      belief,
      mentalEstimations :
        [
          [Delta({v: 0})], /** over agent 0 (kid) */
          undefined /** over oneself */
        ],
      metaParamsEstimations: {
        alpha,
        lookAhead,
        discountFactor
      }
    }
  }
  let getChildParams = function(alpha, discountFactor, lookAhead) {
    return {
      /** format [physical goal, mental goal] */
      goalCoeffs: [1],
      metaParams: {
        alpha,
        discountFactor,
        lookAhead
      }
    }
  }
  let getChildInitialState = function(lookAheadEstimation) {
    let alpha = [undefined, Delta({v: 100})]
    let discountFactor = [undefined, Delta({v: 0.9})]
    let lookAhead = [undefined, Delta({v: lookAheadEstimation})]
    let belief = [
      Delta({v:["belief over oneself"]}),
      Delta({v:[1,0]})
    ]
    return {
      belief,
      mentalEstimations : [undefined, undefined],
      metaParamsEstimations: {
        alpha,
        lookAhead,
        discountFactor
      }
    }
  }
  let getChild = function(alpha, discountFactor, lookAhead, lookAheadEstimation) {
    return {
      params: getChildParams(alpha, discountFactor, lookAhead),
      initialState: getChildInitialState(lookAheadEstimation)
    }
  }
  let getParent = function(firstCoeff, lookAhead, lookAheadEstimation) {
    return {
      params: getParentParams(firstCoeff, lookAhead),
      initialState: getParentInitialState(lookAheadEstimation)
    }
  }

  let names = ['kid','parent']
  let startingState = [['X',0],['O',8],['X',4]]
  let startingState1 = [['X',2],['O',8],['X',4],['O',3],['X',0]]
  let startingState2 = [['O',7],['X',0],['O',8],['X',4]]
  let startingState3 = [['X',6],['O',7],['X',0],['O',8],['X',4]]
  let scenarios = [
    {
      name: '(almost) perfectly rational kid with shortish lookahead (2)',
      agents:
        [
          getChild(100, 0.9, 2, 2),
          getParent(0.1, 3, 2)
        ],
      options: {
        horizon: 9,
        beliefRepresentation: 'discrete'
      },
      // startingState: startingState1,
      gameSpecificParams: {
        stateRepresentation: 'history'
      }
    },
    {
      name: 'params from qest paper: child rationality = 5, discountFactor' +
        ' = 0.7',
      agents:
        [
          getChild(5, 0.7, 2, 2),
          getParent(0.1, 3, 2)
        ],
      options: {
        horizon: 1,
        beliefRepresentation: 'discrete'
      },
      // startingState: startingState,
      gameSpecificParams: {
        stateRepresentation: 'history'
      }
    }
  ]

  let callbacks = {
    final
  }

  let run = function(experimentNumber) {
    assertHasType(experimentNumber, INT_TYPE,
      "lookAheadExperiment: run(): experimentNumber must be an " +
      "index into an array; found: " + toString(experimentNumber))
    assert(experimentNumber >= 0 && experimentNumber < scenarios.length,
      "lookAheadExperiment: run(): experimentNumber out of range: " +
      experimentNumber + "; expected between 0 and " + (scenarios.length - 1))
    let scenario = scenarios.slice(experimentNumber, experimentNumber + 1)
    simulateScenarios(scenario, makeTicTacToe, names, callbacks)
  }

  let runAll = function() {
    simulateScenarios(scenarios, makeTicTacToe, names, callbacks)
  }

  return {
    name: 'parentKidExperiment',
    desc: "Parent plays against a kid",
    scenarios,
    names,
    callbacks
  }
}()

let experiments = [lookAheadExperiment, parentKidExperiment]

processCommandline(argv, experiments)

/** ULTIMATUM GAME
 *  This is a well known two player scenario where the first player
 *  (proposer) is given $10 (or any other amount of money) which they
 *  then have to split with the other player by offering them a
 *  proportion of the endowment. The second player (proposee) can then
 *  accept of reject this proposal.
 *
 *  Standard game-theoretical analysis predicts that proposee will
 *  accept any split that gives them a positive amount, but experiments
 *  show that people typically reject proposals that are unfair.
 *
 *  Therefore, we hypothesize that there must be something else at
 *  stake, apart from money. In particular, we assume the existence
 *  of a moral norm that dictates that a split in this scenario should
 *  be roughly equal, or favour the proposee. A more succinct way of
 *  expressing that is to simply mention the idea of fairness. However,
 *  note that fairness is not as straightforward as dictating that a
 *  split be equal. For example, when proposer is poor and proposee a
 *  millionaire, an unequal split in which proposer keeps majority (or
 *  all) of money would likely be considered fair. Also, without knowing
 *  anything about the agents, a split that offers majority of endowment
 *  to proposee should be considered reasonable, given that it's put
 *  forward by the proposer.
 *
 *  The mental attitude that we introduce is regret. The idea is that
 *  proposee regrets accepting a split if they perceive that split
 *  as unfair (so regret depends on perception of fairness).
 *
 *  Regarding standard game components:
 *  - state is represented as execution history (as usual)
 */

/**
 * Here come game-specific auxiliary functions (if needed)
 */

/** we discretise proposals available to the proposer.
 * we want to avoid there being too many actions, even if
 * endowment is large. hence this function returns discretised
 * proposals, as evenly discretised as possible */
let getProposals = function(endowment) {
  let limit = 10 /** maximal number of different proposals we allow */
  if (endowment <= limit)
    return rangeArray(0, endowment)
  let interval = endowment / limit
  let includeIf = function(acc, n) {
    let arr = acc[0]
    let treshold = acc[1]
    let newTreshold = treshold + interval
    if (Math.abs(treshold - n) < 0.5) {
      return [arr.concat([n]), newTreshold]
    }
    return [arr, treshold]
  }
  let result = reduceL(includeIf, [[0], interval], rangeArray(1, endowment-1))
  return result[0].concat([endowment])
}

let aux2 = function() {

}

/**
 * gameSpecificParams = {
 *   endowment: <number of $ proposer gets>
 * }
 */
let makeUltimatumCSMG = function(gameSpecificParams) {
  let endowment = assertDefinedNotNull(gameSpecificParams.endowment,
  "makeUltimatumCSMG(): endowment undefined")

  let PROPOSER = 0
  let PROPOSEE = 1

  /**
   * Now come functions that describe the mechanics of the game
   */

  /** Actions available to an agent (the owner of *state*
   * - assumed to be unique) in *state*.
   * We assume that the action is the amount going to the proposee
   * in the proposed split. E.g. action 4 when endowment is $10 means
   * proposer offered $4 to the proposee */
  let actions = function(state) {
    let actionsByAgent = [
      getProposals(endowment),
      ['accept', 'reject']
    ]
    return actionsByAgent[turn(state)]
  }

  /** transition function must be probabilistic */
  let transitionFn = function(state, action) {
    let stateUpdate =  (turn(state) == PROPOSER) ?
      {
        proposals: [action].concat(state.proposals)
      } :
      {
        responses : [action].concat(state.responses)
      }
    let nextState = extend(state, stateUpdate)
    return Delta({v: nextState})
  }

  /** returns whose turn it is to take an action at *state*.
   *  this is also referred to as the owner of that state.
   *  players are indentified by nonnegative integer */
  let turn = function (state) {
    if (state.proposals.length > state.responses.length)
      return 1
    return 0
  }

  /** checks whether *state* is the initial state */
  let isInitial = function (state) {
    return state.responses.length === 0 && state.proposals.length === 0
  }

  /**
   * Now comes the "API" of the game.
   * This is a set of functions which are used by our library but
   * whose implementation is game-specific.
   * */
  let API = function() {
    /** return state which preceded *state* in the game, or *state* if it is initial state.
     * If called on initial state, this function can return whatever */
    let getPreviousState = function (state) {
      if (isInitial(state)) return state
      if (turn(state) == PROPOSER)
        return extend(state, {responses : state.responses.slice(1)})
      return extend(state, {proposals : state.proposals.slice(1)})
    }

    /** return action that was taken to get to *state* */
    let getLastAction = function (state) {
      assert(!isInitial(state), "Calling previousAction on initial state")
      if (turn(state) == PROPOSER)
        return state.responses[0]
      return state.proposals[0]
    }

    /** returns the string representation of *state*.
     * (for debugging purposes) */
    let stateToString = function (state) {
      return "{proposals: " + arrayToString(state.proposals) +
        ", responses: " + arrayToString(state.responses) + "}"
    }

    let API = {
      getPreviousState,
      getLastAction,
      isInitial,
      turn,
      stateToString
    }

    return API
  }()

  /**
   *  Now comes physical reward structure.
   *  This should typically be a simple component capturing what,
   *  and how much, physical rewards (money, time, number of sweets
   *  etc) agents receive in each state
   */
  let physicalRewardStructure = function() {

    /** Physical rewards gained by each agent at *state*
     * Should return an array indexed by agentID
     */
    let stateRewards = getConstantFn([[0],[0]])

    /** As above but for action rewards
     */
    let actionRewards = function(state, action) {
      if (turn(state) === PROPOSEE && _.isEqual(action, 'accept')) {
        let proposal = state.proposals[0]
        return [[endowment - proposal], [proposal]]
      }
      return [[0],[0]]
    }

    return {
      actionRewards,
      stateRewards
    }
  }()

  /**
   *  Now comes mental state dynamics model. That's the most important
   *  component, it captures the mental quantities (such as trust, guilt,
   *  pleasure, fairness, reciprocity).
   *  It consists of two components:
   *  (i) Heuristics agents use to estimate mental state of their opponents.
   *    This should be specified as an array of update functions, one for each
   *    mental state. Each update function has
   *    @type (mentalStateValue, estimatingAgent, estimatedAgent, state, action) -> newMentalStateValue
   *  (ii) Mental state computation, i.e. how can actual mental state of an
   *    agent be computed. Each such function that computes some mental state
   *    of an agent has
   *    @type (state, belief) -> mentalStateValue
   */
  let mentalStateDynamics = function() {
    let getLastAction = API.getLastAction
    let getPreviousState = API.getPreviousState
    /**
     */
    let updateRegretEstimation =
      function(prevRegret, estimatingAgentID, estimatedAgentID, state, observation) {
        let lastState = getPreviousState(state)
        let action = getLastAction(state)
        if (estimatingAgentID === 0 && estimatedAgentID === 1) {
          let nextState = sample(transitionFn(lastState, action))
          return computeRegret(estimatedAgentID, undefined, nextState)
        }
      }

    /** */
    let computeRegret = function(agentID, belief, state) {
      /** no regret for proposer */
      if (agentID === PROPOSER) return 0
      if (isInitial(state)) return 0
      if (turn(state) === PROPOSEE) return 0
      let decision = state.responses[0]
      let offer = state.proposals[0]
      let fairOffer = endowment / 2
      if (_.isEqual(decision, 'accept')) {
        /** regret after accepting is high if offer was low
         * for now, assume it's linear */
        if (offer >= fairOffer) return 0
        return -offer / fairOffer
      }
      /** regret after rejecting arises if big amount is offered */
      if (offer < fairOffer) return 0
      return - (offer - fairOffer) / fairOffer
    }

    return {
      estimationHeuristicArr: [ updateRegretEstimation ],
      mentalStateArr: [ computeRegret ],
      mentalUtilities: [
        [[]], /** agent 0 */
        [[1]], /** agent 1 */
      ]
    }
  }()

  let initialState = {
    proposals: [],
    responses: []
  }

  /** belief representation and number of rewards (total = physical + mental)
   * must be specified */
  let params = {
    numberOfAgents: 2,
    numberOfRewards: {
      physical: 1,
      mental: 1
    }
  }

  /** Those are functions that make up the utility function that are
   * applied to each reward to possibly modify its value */
  let rewardUtilityFunctions = function() {
    let moneyUtility = function(x) {
      let scale = endowment / 2
      /** the value of x for which this function evaluates to 1/2 is
       * more or less equal to 'scale' */
      return 2 / (1 + Math.exp(-x/scale)) - 1
    }

    return {
      physical: [moneyUtility],
      mental: [identity]
    }
  }()

  return {
    actions,
    transitionFn,
    initialState,
    physicalRewardStructure,
    mentalStateDynamics,
    rewardUtilityFunctions,
    API,
    params
  }
}
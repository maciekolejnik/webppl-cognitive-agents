/**
 Include here an overview of the modeled scenario
 */

/**
 * Include a description of expected structure of gameSpecificParams
 */
let makeCSMG = function(gameSpecificParams) {
    // let param1 = gameSpecificParams.param1
    // let param2 = gameSpecificParams.param2
    // ...

    /**
     * Here come game-specific auxiliary functions (if needed)
     */
    let aux1 = function() {

    }

    let aux2 = function() {

    }

    /**
     * Now come functions that describe the mechanics of the game
     */

    /** Actions available to an agent (the owner of *state*
     * - assumed to be unique) in *state* */
    let actions = function(state) {
        error("not implemented")
    }

    /** transition function MUST be probabilistic!
     * (use Delta to implement a deterministic one) */
    let transitionFn = function(state, action) {
        error("not implemented")
        // return Delta({v: nextState}) - use this for deterministic
    }

    /**
     * Now comes the "API" of the game.
     * This is a set of functions which are used by our library but
     * whose implementation is game-specific.
     * */
    let API = function() {
        /** return state which preceded *state* in the game, or *state* if it is initial state.
         * If called on initial state, this function can return whatever */
        let getPreviousState = function (state) {
            if (isInitial(state)) return state
            // ...
            error("not implemented")
        }

        /** return action that was taken to get to *state* */
        let getLastAction = function (state) {
            assert(!isInitial(state), "Calling previousAction on initial state")
            // ...
            error("not implemented")
        }

        /** (optional)
         * does *action* taken in *state* end a round?
         * A concept of a round (which is an 'atomic' fragment of a game; it
         * either gets executed fully or not at all) is introduced so that
         * discounting can happen after every round, rather than after every move */
        let endsRound = function (state, action) {
            error("not implemented")
        }

        /** checks whether *state* is the initial state */
        let isInitial = function (state) {
            error("not implemented")
        }

        /** returns whose turn it is to take an action at *state*.
         *  this is also referred to as the owner of that state.
         *  players are indentified by nonnegative integer */
        let turn = function (state) {
            error("not implemented")
        }

        /** returns the string representation of *state*.
         * (for debugging purposes) */
        let stateToString = function (state) {
            error("not implemented")
        }

        let API = {
            getPreviousState,
            getLastAction,
            endsRound,
            isInitial,
            turn,
            stateToString
        }

        return API
    }()

    /**
     *  Now comes physical reward structure.
     *  This should typically be a simple component capturing what,
     *  and how much, physical rewards (money, time, number of sweets
     *  etc) agents receive in each state
     */
    let physicalRewardStructure = function() {

        /** Physical rewards gained by each agent at *state*
         * Should return an array indexed by agentID
         */
        let stateRewards = function(state) {
            /** return [ <rewards of agent 0>, <rewards of agent1>, ...] */
            error("not implemented")
        }

        /** As above but for action rewards
         */
        let actionRewards = function(state, action) {
            /** return [ <rewards of agent 0>, <rewards of agent1>, ...] */
            error("not implemented")
        }

        return {
            actionRewards,
            stateRewards,
        }
    }()

    /**
     *  Now comes mental state dynamics model. That's the most important
     *  component, it captures the mental quantities (such as trust, guilt,
     *  pleasure, fairness, reciprocity).
     *  It consists of two components:
     *  (i) Heuristics agents use to estimate mental state of their opponents.
     *    This should be specified as an array of update functions, one for each
     *    mental state. Each update function has
     *    @type (mentalStateValue, estimatingAgent, estimatedAgent, state, action) -> newMentalStateValue
     *  (ii) Mental state computation, i.e. how can actual mental state of an
     *    agent be computed. Each such function that computes some mental state
     *    of an agent has
     *    @type (state, belief) -> mentalStateValue
     */
    let mentalStateDynamics = function() {

        /** Heuristic is defined by 'update functions' which capture
         * how *estimatingAgent*'s estimation of opponent's (*estimatedAgent*)
         * mental attitude changes as a result of *action* taken in *state*
         */
        let updateMentalAttitude1Estimation =
          function(prevValue, estimatingAgentID, estimatedAgentID, state, action) {
            error("not implemented")
        }

        /** This expresses how the actual value of the mental attitude can
         * be computed, in *state*, based on agent's *belief* */
        let computeMentalAttitude1 = function(agentID, belief, state) {
            error("not implemented")
        }

        return {
            estimationHeuristicArr: [ updateMentalAttitude1Estimation /** , ... */ ],
            mentalStateArr: [ computeMentalAttitude1 /** , ... */ ],
            mentalUtilities: [
              [[/** att 0 */],[/** att 1 */], /** ... */], /** agent 0 */
              [[/** att 0 */],[/** att 1 */], /** ... */], /** agent 1 */
              /** ... */
              [[/** att 0 */],[/** att 1 */], /** ... */], /** agent n */
            ]
        }
    }()

    /** this is optional, use it only when heuristics applies */
    let heuristics = function() {
        /** optional */
        let action = function() {
            let applies = function(state, estimatingAgentID, estimatedAgentID) {
                error('not implemented')
            }

            let computeOpponentAction =
              function(estimatingAgentID, estimatedAgentID, action,
                       state, getMentalState, getMentalEstimation) {
                  error('not implemented')
            }

            return {
                applies,
                computeOpponentAction
            }
        }()


        let belief = function() {
            /** does heuristic apply for updating belief of
             *agent* when *action* taken at state */
            let applies = function(state, action, agent) {
                error('not implemented')
            }

            let updateBelief = function(fullBelief, state, action) {
                error('not implemented')
            }

            return {
                applies,
                updateBelief
            }
        }()

        return {
            action,
            belief
        }
    }()

    /** Defines the initial state of the model (we assume there's only one such) */
    let initialState = undefined // usually an object { ... }

    /** belief representation and number of rewards (total = physical + mental)
     * must be specified */
    let params = {
        numberOfAgents: 2 /** or whatever it is */,
        numberOfRewards: {
            physical: 1,
            mental: 1
        } /** or whatever is the total number of rewards */
    }

    /** Those are functions that make up the utility function that are
     * applied to each reward to possibly modify its value */
    let rewardUtilityFunctions = function() {
        let physicalUtility1 = function(x) {
            // ...
            error("not implemented")
        }

        // ...

        let physicalUtilityk = function(x) {
            // ...
            error("not implemented")
        }

        let mentalUtility1 = function(x) {
            // ...
            error("not implemented")
        }

        let mentalUtilityl = function(x) {
            // ...
            error("not implemented")
        }

        // ... third, fourth etc

        /** the array should contain as many items as there are rewards
         * (mental + physical) */
        return {
            physical: [physicalUtility1, /** ... */physicalUtilityk],
            mental: [mentalUtility1, /** ... */mentalUtilityl]
        }
    }()

    return {
        actions,
        transitionFn,
        initialState,
        physicalRewardStructure,
        mentalStateDynamics,
        heuristics,
        rewardUtilityFunctions,
        API,
        params
    }
}